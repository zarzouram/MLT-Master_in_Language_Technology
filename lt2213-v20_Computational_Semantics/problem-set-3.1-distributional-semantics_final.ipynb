{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributional semantics\n",
    "\n",
    "Mehdi Ghanimifard, Adam Ek, Wafia Adouane and Simon Dobnik\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the instructions on how to work on group assignments.\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below.\n",
    "\n",
    "---\n",
    "\n",
    "In this lab we will look how to build distributional semantic models from corpora and use semantic similarity captured by these models to do some simple semantic tasks. We are going to use the code that we discussed in the class last time.\n",
    "\n",
    "The following command simply imports all the methods from that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dist_erk import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Loading a corpus\n",
    "\n",
    "To train a distributional model, we first need a sufficiently large collection of text which will contain different words used frequently enough in different contexts. Here we will use a section of the Wikipedia corpus which you can download from [here](https://linux.dobnik.net/oc/index.php/s/9NTlpOJfPWGS56t/download?path=%2Flab4-distributional-data&files=wikipedia.txt.zip) (Linux and Mac) or [here](https://linux.dobnik.net/oc/index.php/s/9NTlpOJfPWGS56t/download?path=%2Flab4-distributional-data&files=wikipedia-for-windows.zip) (Windows). (This file has been borrowed from another lab by [Richard Johansson](http://www.cse.chalmers.se/~richajo/).) When unpacked the file is 151mb hence if you are using the lab computers you should store it in a temporary folder outside your home and adjust `corpus_dir` path below.\n",
    "<It may already exist in `/opt/mlt/courses/cl2015/a5`.>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dir = '/home/guszarzmo@GU.GU.SE/LT2213-v20/lab1/lt2213-lab-1-group-3/zarzouram/problem-set-3/wikipedia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Building a count-based model\n",
    "\n",
    "Now you are ready to build a count-based model. The functions for building word spaces can be found in `dist_erk.py`. We will build a model that create count-based vectors for 1000 words. Using the methods from the code imported above build three word matrices with 1000 dimensions as follows: (i) with raw counts (saved to a variable `space_1k`); (ii) with PPMI (`ppmispace_1k`); and (iii) with reduced dimensions SVD (`svdspace_1k`). For the latter use `svddim=5`. **[5 marks]**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Marks=5\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file wikipedia.txt\n",
      "create count matrices\n",
      "reading file wikipedia.txt\n",
      "ppmi transform\n",
      "svd transform\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "word_to_keep = 1000\n",
    "num_dims = 1000\n",
    "svddim = 5\n",
    "\n",
    "# which words to use as targets and context words?\n",
    "ktw = do_word_count(corpus_dir, word_to_keep)\n",
    "\n",
    "wi = make_word_index(ktw) # word index\n",
    "words_in_order = sorted(wi.keys(), key=lambda w:wi[w]) # sorted words\n",
    "\n",
    "print('create count matrices')\n",
    "space_1k = make_space(corpus_dir, wi, num_dims)\n",
    "print('ppmi transform')\n",
    "ppmispace_1k = ppmi_transform(space_1k, wi)\n",
    "print('svd transform')\n",
    "svdspace_1k = svd_transform(space_1k, num_dims, svddim)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Bulding a word2vec model\n",
    "\n",
    "We will also build a continuous-bag-of-words (CBOW) word2vec model using gensim (https://radimrehurek.com/gensim/index.html). Build a CBOW word2vec model, where each word have 300 dimensions and as above, limit the vocabulary size to the most common 1000 words. **[5 marks]**\n",
    "\n",
    "Documentation for the Word2Vec class can be found here: https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# gensim require a iterable class to process the corpus\n",
    "class CorpusReader():\n",
    "    def __init__(self, corpus_path):\n",
    "        self.corpus_path = corpus_path\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.corpus_path):\n",
    "            sentence = utils.simple_preprocess(line)\n",
    "            if sentence:\n",
    "                yield sentence \n",
    "            \n",
    "corpus = CorpusReader(corpus_dir+'/wikipedia.txt')\n",
    "w2v_model = Word2Vec(sentences=corpus,\n",
    "                     # training options goes here\n",
    "                     size=300, max_final_vocab=num_dims, window=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Marks=5\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house: [2554 3774 3105  567  962  631  443  185  311  189  131   28   93  169\n",
      "   81  125  151  408  194   90   79   29  217  184   62   15   31   70\n",
      "   10    1   41   21    1   31   37    1   30    5   25    7    3   20\n",
      "   11    1   32   36    2    5   66    4    0   46    8   18   28    0\n",
      "   20    7    8   16   10   40    0  175   10    2    7   19    1  174\n",
      "   11    3    1    6    0    0    0   10    9   11    7   24    4    4\n",
      "   14   23   58    7    0   10    2    3   10    6   18    6   13    3\n",
      "   22    0    3    5    3    7   14    3   40   20   19   15    6    8\n",
      "   24    4    5    1   19    0    3    1    0   14    0   14   53    7\n",
      "    7   11    6    5    5    4   12    6   53    1    1  433    4    0\n",
      "    5    7    7   12    1    1    3    4   17    8   16    1    2   31\n",
      "    1   12   14    1   44    6   14    9   38    7    2    6    8    1\n",
      "   10    6   10    1    9    7    9    4    3   10    0   11    3    2\n",
      "    0    2   11   37    2    0    2    1    5    9   10   16   88    6\n",
      "    0   21    1    1    0    2   47    3   27    7    0    2   13    1\n",
      "    2    0    5   31    0    1    0    3   10    0    1    0    3    3\n",
      "   17    1    1   16    3    7    4    7   15    4    0    0    2    5\n",
      "    0    2    0    5    0    9    0    0    8    0   10    0    0    0\n",
      "    2    0    1    3    1    3   15    1    9    0   19   14    0    0\n",
      "    3    2   18    3    1    3    2   19    5    2    4    1   10    6\n",
      "    0    3    3    6    4    2   25    4    6    3    1   25   10   15\n",
      "    3   10   15    1   10    1    8    1   13    1    2    9    9    1\n",
      "    4    1   25    0    4    6    5    5   36    0    2    2    2    0\n",
      "    0    2    3    3    0    1    4    6    5    0   50    2    5    2\n",
      "   14    6    2    2    4    1    9    4    5    3    1    0   12    3\n",
      "    3    2    2    0    0    1    4    7   12    5    0    2    1    2\n",
      "    3    4    7    3    5    0   29    7    1    1    0    3    3    3\n",
      "   10    0   14    2    0    2    4    6    0    5    0    0    1    1\n",
      "    4    1    1    0    0    0    0    3   20    0    0    2    1    5\n",
      "    3    8    3    5    1    2   66    1    2   19    2    1    3    3\n",
      "   21    5    4    2    2    0    4    3    5    0    7    1    6    1\n",
      "    3    3    1    0    3    0    2    0   89    2    3    1    1   14\n",
      "    0    2    1    9    2    3    2    4    2    0   25    0    0   23\n",
      "    0    6    2    1    3    0    2    5    0    4    4    3    0    4\n",
      "   58    3    1    6    2    4    3    3   11    1    1    1   10    0\n",
      "    7    3    1    6    1   18    1    0    4    2    0    8    5    2\n",
      "    0    0    0    0    5    1    2    1    1    3    1    2    1    1\n",
      "    0    6    1    4    1    3   20    1    0    5    2    5    2    1\n",
      "    0    0    0    2    6    1    1    0    1    1    1    0    0    3\n",
      "    3    0    0    6    6   74    3    0   13    5    2    2    1    5\n",
      "    3    3    1    7    4    0    0    2    3    0    4    0    4    1\n",
      "    0    2    5    2    1   14    2    0    0   19    0    1    2    1\n",
      "    0    3    2    0    0    3    1    3    3    2    7   18    7    6\n",
      "    6    0    1    9    1   10    2    0    2    0    2    4    0    0\n",
      "    1    2    0    1    0    2    0    0    0    2    1    2    2    0\n",
      "    3    2    2    0    0    1    2    3    1    1    1    2    0    0\n",
      "    3    0    7    2   39    0   14    0    1    1    0    1    5    3\n",
      "   11    0    3    0    1    1    0    0    1    9    2    1    0   11\n",
      "    1    3    7    0    0    0   32    1    0    0    0    1    1    3\n",
      "    0    9    0    2    0    1    3    2    6    0    3    0    0    2\n",
      "    3    0    1    0    1    4    0    0    1    1    0    0    5   21\n",
      "    2    1    1    3    0    1    7    1    3    4    0    5    3    0\n",
      "    7    2    0    4    2    0    2    1    4    4    0    0    0    5\n",
      "    3    2    2    0    4    0   23    2    2    2    4    0    1    0\n",
      "    4    0    3    5    3    0    8    0    1   16    1    2    2    7\n",
      "    0    0    1   11    1    0    4    0    1    0    1    2    1    5\n",
      "    0   97    0    2    0    3    0    8    1   14    4    9    2    3\n",
      "    1    1    0    3    4    0    5    1    5    2    0    0    0    2\n",
      "    1    2    1    1    1    1   12    0    2    5    1    0    0   13\n",
      "    2    0    0    0    2    2    0    0    3    1    1    1    1    0\n",
      "    1    2    1    0    0    0   10    0    1    0    1    1    1    1\n",
      "    0    1    0    0    3    2    5    0    0    2    1    0   23    0\n",
      "    0    4    0    1    0    0    0    1    1    2    1    0    1    0\n",
      "    0    4    1    0    1    1    5    1    1    0    1    0    0    0\n",
      "    1    0    0    2    2    3    0    1    0    4    3    3    1    4\n",
      "    0    0    0    6    1    2    1    0    5    3    0    0    1    2\n",
      "    0    5    0    0    2    1    1    4   15    0    0    1    1    3\n",
      "    1    0    1    4    1    1    2    8    1    3    0    0    0    0\n",
      "    1    3    2    1    0    1    0    2    0    0    0    0    1    1\n",
      "    0    1    3    7    0    0   42    4    0    1    2    3    1    0\n",
      "    1    3    2    0    0    4    0    0    0    4    2    0    0    8\n",
      "    2    0    1   15    0    0]\n",
      "house: [ 0.06746601  0.38757306 -0.49925327  0.27870387 -0.64003086 -0.1009874\n",
      "  0.4933308  -0.16721977 -0.5412252  -1.0207652  -0.35549814 -0.27909252\n",
      " -0.29937068  0.26058632  0.03211487 -0.15240298  0.49682865  0.41746095\n",
      " -0.1364108   0.4904845   0.5823948   0.1426506  -0.47868925 -0.10418355\n",
      "  0.51148784 -0.42320675  0.24402002 -0.840878   -0.12018277 -0.05887187\n",
      "  0.1519347   0.39610866 -0.27096835 -0.12342257  0.34274817 -0.24877214\n",
      " -0.42367953 -0.00977793  0.11664203 -0.1478846   0.4521189  -0.21814963\n",
      "  0.82043624  0.39034322 -0.18472567  0.04092524  0.9835037  -0.15023516\n",
      "  0.49568397  0.38227153 -0.29262066 -0.35779104 -0.312153    0.4503958\n",
      "  0.41612026  0.57846045 -0.25915453  0.7435352  -0.29619324  0.20546141\n",
      "  0.3235146  -0.6901372   0.07962132  0.39070112 -0.3142039   0.848221\n",
      " -0.14396779 -0.7275229  -0.5429388   0.52585095 -0.6712891   0.8836946\n",
      " -0.33710453 -0.514954   -0.3470575   0.79605985 -0.3457802  -0.01727695\n",
      "  0.47531456  0.17853872 -0.7449793  -0.18243662 -0.5347068   0.38205716\n",
      " -0.04640386 -1.0157425   0.16415897 -0.30421895 -0.35129434  0.43377542\n",
      "  0.21424848  0.7163966  -0.2587985   0.29612088 -0.3942672  -0.08263583\n",
      "  0.47817415  0.13106309  0.10828267 -0.4527085  -0.63872606  0.15384725\n",
      " -0.09926212 -0.56686974 -0.3261824  -0.9300956  -0.20437163  0.42015785\n",
      " -0.33532456 -0.38065183  0.2577155   0.30517322 -0.18147768  0.15133049\n",
      " -0.20966393  0.14823644  0.5832299  -0.12748906 -0.48805654  0.6398459\n",
      "  0.22463875  0.06505781 -0.24733303 -0.13240992 -0.38961864  0.50835294\n",
      " -0.41773292 -0.01048832  0.25281858  0.42013863 -0.07040023  0.04946611\n",
      " -0.14122538 -0.04478065 -0.60797864  0.10286177  0.42696604 -0.31043804\n",
      " -0.14360821  0.0887005   0.39322248 -0.59088475  0.09361824  0.54895204\n",
      " -0.01294939  0.1127428   0.1759893   0.27367723 -0.51660496  0.34304097\n",
      " -0.49363407  0.37938422  1.2761974  -0.25902027  0.37585235 -0.40980175\n",
      " -0.3277706  -0.9590475  -0.110379   -0.7125715  -0.10900878  0.18589857\n",
      " -0.19487336  0.01502023 -0.05424795  0.00443935  0.61875176  0.68144387\n",
      "  0.08348195 -0.5535747   0.1841225   0.5480076   0.18997705 -0.48678964\n",
      " -0.30176815  0.59574085  0.01253685 -0.18853584 -0.17478013  0.15637127\n",
      " -0.19106399 -0.95572996 -0.59512055  0.01110383 -0.18138662 -0.00619916\n",
      " -0.20264916  0.9973594   0.06979059 -0.13136324  0.07422638 -0.94600594\n",
      " -0.7322963   0.36467138 -0.07816479 -0.10495736  0.8995916   0.02414061\n",
      " -0.17985527 -0.64446586  0.7120791  -0.45236266 -1.1154925  -0.93966126\n",
      " -0.18207625 -0.3134863  -0.4194132  -1.1211077  -0.20843549 -0.7968608\n",
      " -0.08627412 -0.24043313 -0.25616947  0.05576359  0.08524158 -0.9346338\n",
      " -0.3940039   0.49729     0.8684074  -0.74599576  1.2103568   0.43417647\n",
      " -0.01473453 -0.01076994  0.5697158   0.28738752  0.2299306  -0.85805154\n",
      " -0.64793533 -1.4509794   0.05168957 -0.15686725 -0.17454582 -0.27299282\n",
      " -0.30067945  0.37252298 -0.7604486  -0.430804    0.12938905 -0.4212178\n",
      "  0.00426435  0.20737559 -0.4921483   0.46482733 -0.67147166  0.08852333\n",
      " -0.10489782  0.54811704 -0.46996406 -0.0560461  -0.09688537 -0.0205392\n",
      "  0.2957226   0.00954135  0.44363227 -0.07087088  0.20160255 -0.06097046\n",
      "  0.3369312   0.5804282   0.7833369  -0.36444917  0.40028054 -0.49462008\n",
      " -0.62914723  0.74258167 -0.12294261 -0.8162855  -0.46232927 -0.25734508\n",
      " -0.934782   -0.05537856  0.81474096 -0.02900121 -0.33662224 -0.13612309\n",
      " -0.83924425  0.13020508 -1.1651264   0.02009203 -0.18094134 -0.14193012\n",
      "  0.80651766 -0.20152746  0.9519605   0.65998703 -1.0883607   0.01980958\n",
      " -0.48045263 -0.36553186  0.16888796  0.2453423  -1.0383462   0.12327282\n",
      "  0.19749299 -0.43589947 -0.0544695  -0.5295069  -1.0534917   0.29052544]\n"
     ]
    }
   ],
   "source": [
    "print('house:', space_1k['house'])\n",
    "print('house:', w2v_model['house'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oxford Advanced Dictionary has 185,000 words, hence 1,000 words is not representative. We trained a model with 10,000 words, and 50 dimensions on truncated SVD. It took 40 minutes on a laptop. \n",
    "\n",
    "Additionally, we trained a word2vec model on the same data. The vocabulary size is also 10,000 with 300 dimensions for the words, and truncated to 50 dimensions in SVD. It took about 15 minutes on a desktop.\n",
    "\n",
    "We saved all five matrices [here](https://gubox.app.box.com/folder/75208243314) ([alternative/old link](https://linux.dobnik.net/oc/index.php/s/9NTlpOJfPWGS56t/download?path=%2Flab4-distributional-data&files=pretrained.zip)) which you can load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait..\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numdims = 10000\n",
    "svddim = 50\n",
    "\n",
    "basepath = \"/home/guszarzmo@GU.GU.SE/LT2213-v20/lab1/lt2213-lab-1-group-3/zarzouram/problem-set-3/\"\n",
    "\n",
    "print('Please wait..')\n",
    "ktw_10k       = np.load(basepath+'pretrained/ktw_wikipediaktw.npy', allow_pickle=True)\n",
    "space_10k     = np.load(basepath+'pretrained/raw_wikipediaktw.npy', allow_pickle=True).all()\n",
    "ppmispace_10k = np.load(basepath+'pretrained/ppmi_wikipediaktw.npy', allow_pickle=True).all()\n",
    "svdspace_10k  = np.load(basepath+'pretrained/svd50_wikipedia10k.npy', allow_pickle=True).all()\n",
    "w2v_space     = np.load(basepath+'pretrained/w2v.npy', allow_pickle=True)\n",
    "w2v_svd_space = np.load(basepath+'pretrained/w2v_svd.npy', allow_pickle=True)\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector space can be queried as a dictionary $\\texttt{(word_form: vector, ...)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house: [2554 3774 3105 ...    0    0    0]\n",
      "house: [-0.22926676  0.84213424  0.41197702  0.8781869   1.2811967  -1.4847856\n",
      "  1.4102424   0.7267851  -0.5590538   0.04928471  1.8261132  -0.4911551\n",
      "  2.6236389  -0.62284136 -1.4621106   1.1592358   1.0392265  -0.07465155\n",
      "  1.0108253   1.1842203  -1.5743443  -1.3098637  -0.04264146 -0.1076067\n",
      "  0.5574365   0.7599903   0.11031609  0.16449381 -0.40311787 -0.68341875\n",
      "  0.48706874 -0.73431605 -0.2089108  -0.10828558 -0.6296254   1.3785347\n",
      " -0.2206072  -1.0867819  -0.2650222  -0.18507054 -1.6295078  -1.0952461\n",
      "  1.2633797   0.29369423 -0.10325834  1.2930017   0.83000755 -0.14103375\n",
      "  1.786327    0.49764258 -2.0428705   0.64002794 -0.3000837   0.03268864\n",
      " -0.0933575   0.76802623 -0.1682042   1.8946133  -0.10339233  0.78187567\n",
      " -0.28241557 -1.0668939   2.4631667   1.0492538   0.10093345  0.5764743\n",
      " -0.24940039 -0.27094615 -0.5501715  -0.07181013  0.830345    0.06051366\n",
      " -0.75200856  0.03423605  0.12481829  0.35145602 -0.5419142   0.62099475\n",
      " -0.05916285 -0.19540095 -1.824948   -0.9549101   0.7577381  -0.38998654\n",
      " -0.991503   -0.30834386  0.3275724   0.43987712 -0.4884273   0.64058024\n",
      " -0.7868578   1.2572296  -2.1773124  -0.9416153   0.3610698   0.4525526\n",
      " -0.74326986  0.17008787  0.13389921  0.5462773   0.22158578  0.96646893\n",
      " -0.7076577   1.0714767   1.0601343  -1.1172956   0.52038205  0.25404415\n",
      "  0.6282369   1.1315012   1.4397461  -1.8375728   0.03305732 -0.730534\n",
      " -0.8909393  -1.0816691  -1.4132217   0.3262256   0.8700905  -0.30414504\n",
      " -1.5354352   0.11356701 -1.1209993  -0.3432277  -0.28034794  0.29500887\n",
      "  0.18721093  0.2440819  -1.7600738  -0.88288015  0.97310877  1.2320257\n",
      " -2.2670896   1.4865086  -0.5700085   1.164806    1.0586189   0.14098446\n",
      " -0.355204   -0.01398894  0.41787666 -0.32915497  0.42694667  2.0801284\n",
      " -2.1506665   1.0133879   1.0759456   0.9264778  -1.2152892  -0.6602847\n",
      "  0.5060731  -0.32094598 -0.28988057 -0.7394317  -2.0207496   0.71306926\n",
      "  1.2402455  -0.24515495 -0.37114933  1.5931996  -0.6360829  -1.4725424\n",
      " -0.11482902 -1.8906887  -0.54170257 -0.55295926  1.4443214  -0.23814447\n",
      " -0.48672342 -0.5407612   0.42850202  0.13757505 -0.02138608 -1.6466916\n",
      " -0.1910228   0.46083194  0.42380738  0.47265923 -1.1858094  -0.6227363\n",
      "  0.54788095 -1.0688363  -0.1841182  -0.08076867 -0.52222496  0.7198857\n",
      "  0.90227884  0.58870053 -0.43280578  1.5541542  -1.097152    1.3715382\n",
      "  0.27046102  1.6903312   0.04087806 -0.69100976  0.9679937  -0.8470927\n",
      " -1.1461766   0.02025647 -1.3694992  -0.44830137 -0.80377305  0.4249456\n",
      " -1.4186532  -0.3481928   0.19753239 -0.8729285  -1.5973473   1.1367882\n",
      " -0.41963372 -0.6037129  -0.33894223 -1.3070797   0.12363753 -0.43385503\n",
      " -1.8637257   1.4995072  -0.5509144   0.5141327  -0.06147667 -0.0131802\n",
      " -0.7573055   1.7510277  -1.0643308  -0.63295656 -1.064991    1.0223176\n",
      " -0.71696764  0.5522713  -0.06373077  0.23441415  0.85623664 -0.56860155\n",
      " -0.11783724 -0.8743623   0.6011444  -0.05577481 -1.9991608   0.7425451\n",
      "  0.37548137  0.56623465 -0.5068199  -0.1673609  -1.3793486  -1.2628069\n",
      " -0.64876103 -0.6869118  -0.25955796  1.4052316  -2.17065     0.79150665\n",
      " -0.39176947  2.504653    0.08094509  0.7164684  -1.5715998  -1.1838112\n",
      "  0.01541841  1.3190931  -0.2541383  -0.96443075  0.26602322 -1.5274041\n",
      " -0.08827151  0.4345104  -0.90708536  0.08691105 -0.25563017  1.8950318\n",
      "  0.44592023 -0.69715744 -0.7586189   0.20796522  0.9038473   0.30558228\n",
      "  0.14890039 -0.10012661 -0.83041894  1.8578987  -0.35939705 -0.21047702\n",
      "  1.1825349   0.21123861 -0.8749253   0.09556534  0.15295361 -1.065538\n",
      " -0.131343    0.6580647  -0.1913644   1.1124527  -0.68274796 -0.8923838\n",
      " -0.15666054  0.40091816 -0.7420015   0.5618306  -0.1739613  -0.14627855]\n"
     ]
    }
   ],
   "source": [
    "print('house:', space_10k['house'])\n",
    "print('house:', w2v_space['house'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Operations on similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform mathematical operations on word vectors to derive meaning predictions. For example, we can subtract the normalised vectors for `king` minus `queen` and add the resulting vector to `man` and we hope to get the vector for `woman`. Why? **[3 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### Answer:\n",
    "\n",
    "We expect that the relation between `king` and `queen` is the same as `man` and `woman`.  In other words, the similarity (quantified as distance in vector space) between the `king_vector` and the `queen_vector` should be equal to the similarity between the `man_vector` and the `woman_vector`. Thus, we expect that adding the difference between `king_vector` and `queen_vector` to the `man_vector` will move the `man_vector` to be close to `woman_vector`.\n",
    "\n",
    "However, although the `woman` vector appears in the closest space to the `king - queen + man`, further analysis suggests that the calculated vector does not represent the `woman` vector. We think that what we can get from the algebric manipulation described above is the space that contains vectors related to `king`, `queen`, `man` and `woman`. Context words \"features\" that differentiate the `king` and `queen`, which are then added to the `man` are the main factors that affect the output vectors. Please see our analysis below for furtehr detailed discussion.\n",
    "\n",
    "**Note:** The cell's location, which contains the functions `normalize()` and `find_similar_to()`, has been changed so we can use it to the answer of question 3.\n",
    "\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Clear answer! Marks=3\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some helpful code that allow us to calculate such comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def normalize(vec):\n",
    "    return vec / veclen(vec)\n",
    "\n",
    "def find_similar_to(vec1, space):\n",
    "    # vector similarity functions\n",
    "    sim_fn = lambda a, b: 1-distance.euclidean(normalize(a), normalize(b))\n",
    "    # sim_fn = lambda a, b: 1-distance.correlation(a, b)\n",
    "    # sim_fn = lambda a, b: 1-distance.cityblock(normalize(a), normalize(b))\n",
    "    # sim_fn = lambda a, b: 1-distance.chebyshev(normalize(a), normalize(b))\n",
    "    # sim_fn = lambda a, b: np.dot(normalize(a), normalize(b))\n",
    "    # sim_fn = lambda a, b: 1-distance.cosine(a, b)\n",
    "\n",
    "    sims = [\n",
    "        (word2, sim_fn(vec1, space[word2]))\n",
    "        for word2 in space.keys()\n",
    "    ]\n",
    "    return sorted(sims, key = lambda p:p[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.2804240584373474),\n",
       " ('king', 0.010552525520324707),\n",
       " ('himself', -0.09425520896911621),\n",
       " ('boy', -0.11881411075592041),\n",
       " ('woman', -0.12057375907897949),\n",
       " ('son', -0.12237465381622314),\n",
       " ('prophet', -0.12315809726715088),\n",
       " ('hero', -0.12349879741668701),\n",
       " ('nephew', -0.1237407922744751),\n",
       " ('gentleman', -0.13512647151947021)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................  WomanC-Woman    womanC-man     woman-man    queen-king    WomanC-max  \n",
      "    Normalized          0.6988         0.4487        0.5402        0.5764        1.0000    \n",
      "  Not Normalized        0.7118         0.4874        0.4372        0.4874        1.0000    \n"
     ]
    }
   ],
   "source": [
    "# Your code should go here...\n",
    "king = w2v_space['king'];               king_norm = normalize(king)\n",
    "queen = w2v_space['queen'];             queen_norm = normalize(queen)\n",
    "man = w2v_space['man'];                 man_norm = normalize(man)\n",
    "woman = w2v_space['woman'];             woman_norm = normalize(woman)\n",
    "# boy = w2v_space['boy'];                 boy_norm = normalize(boy)\n",
    "\n",
    "# Calculate man+queen-king\n",
    "woman_cal = king - queen + man\n",
    "woman_cal_norm = normalize(woman_cal)\n",
    "\n",
    "# Find similar vectors in the space\n",
    "similar_vectors = find_similar_to(woman_cal_norm, w2v_space)\n",
    "max_dis = similar_vectors[-1][0]\n",
    "display(similar_vectors[:10])\n",
    "# display(similar_vectors[-10:])\n",
    "\n",
    "# Similarity function based on Euclidean distance\n",
    "mysim_fn = lambda a, b: distance.euclidean(a, b)\n",
    "\n",
    "# get the word that has the maximum distance from woman calculated vector\n",
    "max_vector = w2v_space[max_dis];       \n",
    "max_norm = normalize(max_vector)\n",
    "\n",
    "s_max_norm = mysim_fn(woman_cal_norm, max_norm)\n",
    "s_max = mysim_fn(woman_cal, max_vector)\n",
    "\n",
    "# Compare different vectors\n",
    "# Using Normalized Vectors\n",
    "print(\"{:.^19} {:^15} {:^13} {:^13} {:^13} {:^13}\".format(\".\", \"WomanC-Woman\", \"womanC-man\", \"woman-man\", \"queen-king\", \"WomanC-max\"))\n",
    "s0 = mysim_fn(woman_cal_norm, woman_norm) / s_max_norm\n",
    "s1 = mysim_fn(woman_cal_norm, man_norm) / s_max_norm\n",
    "# s2 = mysim_fn(woman_cal_norm, boy_norm) / s_max_norm\n",
    "s3 = mysim_fn(woman_norm, man_norm) / s_max_norm\n",
    "s4 = mysim_fn(queen_norm, king_norm) / s_max_norm\n",
    "s5 = mysim_fn(woman_cal_norm, max_norm) / s_max_norm\n",
    "\n",
    "print(\"{:^19} {:^15.4f} {:^13.4f} {:^13.4f} {:^13.4f} {:^13.4f}\".format(\"Normalized\", s0, s1, s3, s4, s5))\n",
    "\n",
    "# Using non normalized vectors\n",
    "s10 = mysim_fn(woman_cal, woman) / s_max\n",
    "s11 = mysim_fn(woman_cal, man) / s_max\n",
    "# s12 = mysim_fn(woman_cal, boy) / s_max\n",
    "s13 = mysim_fn(woman, man) / s_max\n",
    "s14 = mysim_fn(queen, king) / s_max\n",
    "s15 = mysim_fn(woman_cal, max_vector) / s_max\n",
    "print(\"{:^19} {:^15.4f} {:^13.4f} {:^13.4f} {:^13.4f} {:^13.4f}\".format(\"Not Normalized\", s10, s11, s13, s14, s15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further disscussion on the algebric manuplation \"`king - queen + man`\"\n",
    "\n",
    "In the code above, we use the Euclidean distance as a similarity function. The \"`calculated woman`\" is equal to `king - queen + man`.\n",
    "\n",
    "We then search for words whose vectors are similar to the \"`calculated woman`\" vector. As expected, the `woman` vector appears in the closest space to \"`calculated woman`\". Interestingly, other vectors show up, such as `man`, `king`, `himself` and `boy`.  The word `boy` is the closest word vector to the \"`calculated woman`\". Also, words like `son`, `prophet`, `gentlemen` appear. These words have a masculine gender feature. This result is inconsistent with the intuition of getting `woman` because of gender influence on context.\n",
    "\n",
    "We compared the `calculated woman` and the `women` vectors to examine to what degree they are similar, see the table in above cell. We normalized the Euclidean distance to the maximum distance found in our vector space. As expected, the similarity between `king` and `queen` is reasonably equal to the similarity between `man` and `woman`. We noticed that the `calculated woman` is closer to `man` than the original `woman` vector. \n",
    "\n",
    "The last result, in addition to the words that are found to be more corrlated to the calculaed vector, suggest that the calculated vector may do not represent the `woman` vector. \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "--- AE: So, what to consider when working with distributed vectors is that they wont give the EXACT location of woman, they will give an approximate location (kinda: \"woman\" should be around here). The ofcourse, based on the content of the corpora, and the method used, other words may lie in this area, or region, which that the algebraic manipulation points at. \n",
    "\n",
    "I'm also wondering abit about your division with s_max/s_max_norm, and the \"max_distance\" thing in general. I don't really understand your reasoning for dividing the similarity with this, what does this add to your analysis? \n",
    "\n",
    "The results are abit confusing, so the similarity between the calculated vector for woman (`womanC`) is higher with `Woman` (.69) than to `man` (.44) in your table? So, `woman` is more similar to `womanC` than `man`?\n",
    "\n",
    "In general tho, I think it's an interesting idea for analysing vector spaces (which is kinda fun!), but you need to motivate the method behind the analysis abit more. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you apply this code. Compare the count-based method with the word2vec method and comment on the results you get. **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king', 0.30582571029663086),\n",
       " ('isabella', 0.05993384122848511),\n",
       " ('queen', 0.05481141805648804),\n",
       " ('regent', 0.024451017379760742),\n",
       " ('consort', 0.006222903728485107),\n",
       " ('princess', -0.006409406661987305),\n",
       " ('aragon', -0.02746891975402832),\n",
       " ('woman', -0.040259361267089844),\n",
       " ('prince', -0.044527292251586914),\n",
       " ('throne', -0.04945361614227295)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count based\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('king', 0.7203524622658145),\n",
       " ('master', 0.6998342452614426),\n",
       " ('group', 0.6798995313375658),\n",
       " ('legacy', 0.678797007381283),\n",
       " ('bishop', 0.6705391829560815),\n",
       " ('wizard', 0.6702145341927735),\n",
       " ('great', 0.6683195163949522),\n",
       " ('chronology', 0.6651789427826227),\n",
       " ('shadow', 0.6631569577811421),\n",
       " ('prophecy', 0.660960082400398)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "king = normalize(w2v_space['king'])\n",
    "queen = normalize(w2v_space['queen'])\n",
    "man = normalize(w2v_space['man'])\n",
    "woman = normalize(w2v_space['woman'])\n",
    "\n",
    "w2v = find_similar_to(king - man + woman, w2v_space)[:10]\n",
    "\n",
    "king = normalize(space_10k['king'])\n",
    "queen = normalize(space_10k['queen'])\n",
    "man = normalize(space_10k['man'])\n",
    "woman = normalize(space_10k['woman'])\n",
    "\n",
    "count = find_similar_to(king - man + woman, space_10k)[:10]\n",
    "\n",
    "print(\"word2vec\")\n",
    "display(w2v)\n",
    "print(\"count based\")\n",
    "display(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### Answer:\n",
    "\n",
    "The word2vec is more capable of capturing words related to `king - man + woman` such as isabella, queen, princess, prince, and throne. The word2vec method seems to capture the meaning relations we expect from the \"king-man+woman\" and has words like \"queen\", \"Isabella\" (supposedly a queen Isabella), or \"princess\" in the top 10 results. Interestingly, \"king\" remains in first place, with a significantly higher score than the second-highest, Isabella. In contrast, the count-based method does not confirm our intuition about meaning here at all and instead gives words that often occur in a similar context as \"king\", such as \"master\", \"bishop\", or \"great\". These word relations seem to be taken from the context of fantasy books, films, or computer games and don't correspond to the typical associations one would have with \"real-world\"-kings (or queens). However, these results have very relatively high confidence score.\n",
    "\n",
    "Word2vec is a predict-based model that predicts a word based on context words surrounding it. Thus, the model is more capable of learning words related to each other than the count-based model, which relies on counting wording that appears with each other. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Marks=4\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find 2 similar pairs of pairs of words and test them. Does the resulting vector similarity confirm your expectations? But remember you can only do this if the words are contained in our vector space. **[2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('noon', 0.3371831394944971),\n",
       " ('moon', 0.1947421521774182),\n",
       " ('midnight', 0.18643548055835057),\n",
       " ('night', 0.1732825223598521),\n",
       " ('nights', 0.15294529026537618),\n",
       " ('dawn', 0.11412533982372974),\n",
       " ('morning', 0.10290676720109992),\n",
       " ('pm', 0.09467113661912308),\n",
       " ('mars', 0.08986970536185568),\n",
       " ('lunar', 0.07473034257418476)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noon = normalize(w2v_svd_space['noon'])\n",
    "sun = normalize(w2v_svd_space['sun'])\n",
    "moon = normalize(w2v_svd_space['moon'])\n",
    "\n",
    "find_similar_to(noon - sun + moon, w2v_svd_space)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### Answer:\n",
    "\n",
    "Word2Vec finds vectors for words that are related to night such as night, midnight, pm and dawn.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Marks=1\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the number of dimensions, and the window size in the models you built in (2.1) and (2.2). Comment on the new results you get in comparison to the first results results. [**4 marks**]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window = 2, Number of Word = 1000, Reduced Dimention = 300, Word3Vec size = 300\n",
      "Count-based Reduced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mother', 1.0),\n",
       " ('father', 0.7849403673208615),\n",
       " ('brother', 0.7500760451729602),\n",
       " ('death', 0.6416708056325708),\n",
       " ('wife', 0.6275464846826474),\n",
       " ('son', 0.619609781934459),\n",
       " ('life', 0.6078508816798458),\n",
       " ('daughter', 0.570165359578929),\n",
       " ('personal', 0.5597811250978723),\n",
       " ('works', 0.5572185235230924)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mother', 1.0),\n",
       " ('father', 0.3792811632156372),\n",
       " ('daughter', 0.26224279403686523),\n",
       " ('wife', 0.24355071783065796),\n",
       " ('son', 0.1880810260772705),\n",
       " ('brother', 0.12326663732528687),\n",
       " ('child', 0.08178287744522095),\n",
       " ('death', -0.03311812877655029),\n",
       " ('queen', -0.035846829414367676),\n",
       " ('her', -0.04848647117614746)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "reading file wikipedia.txt\n",
      "create count matrices\n",
      "reading file wikipedia.txt\n",
      "svd transform\n",
      "create Word2Vec\n",
      "Finished creating new models.\n",
      "----------\n",
      "\n",
      "Window = 5, Number of Word = 3000, Reduced Dimention = 500, Word3Vec size = 500\n",
      "\n",
      "Count-based Reduced\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mother', 0.9999999999999998),\n",
       " ('father', 0.8140425061064158),\n",
       " ('brother', 0.7550573380088922),\n",
       " ('sister', 0.7314683289735222),\n",
       " ('wife', 0.7021246708442017),\n",
       " ('death', 0.6833624612820793),\n",
       " ('parents', 0.660287021048755),\n",
       " ('writings', 0.65710866333699),\n",
       " ('successor', 0.657003946296038),\n",
       " ('life', 0.6241045227685684)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Word2Vec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mother', 1.0),\n",
       " ('father', 0.34551578760147095),\n",
       " ('daughter', 0.2779615521430969),\n",
       " ('wife', 0.21182197332382202),\n",
       " ('son', 0.17281436920166016),\n",
       " ('child', 0.15633940696716309),\n",
       " ('parents', 0.13318002223968506),\n",
       " ('sister', 0.11209118366241455),\n",
       " ('brother', 0.07305717468261719),\n",
       " ('friend', 0.05141681432723999)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(words_in_order[:100])\n",
    "print(\"Window = 2, Number of Word = 1000, Reduced Dimention = 300, Word3Vec size = 300\")\n",
    "\n",
    "myword = \"mother\"\n",
    "\n",
    "# making size of count based word embedding equal to the size of Word2Vec\n",
    "svdspace1_1k = svd_transform(space_1k, 1000, 300)\n",
    "# find 10 most words that are similar to myword using count-based model\n",
    "word_v = normalize(svdspace1_1k[myword])\n",
    "\n",
    "########################################\n",
    "### AE note to self: comparison between count-1000-context + svd-300 and original w2v\n",
    "\n",
    "print(\"Count-based Reduced\")\n",
    "display(find_similar_to(word_v, svdspace1_1k)[:10])\n",
    "\n",
    "# find 10 most words that are similar to myword using word2vec model\n",
    "# convert w2vecmodel to dict \n",
    "w2v_dict = dict({})\n",
    "for key in w2v_model.wv.vocab:\n",
    "    w2v_dict[key] = w2v_model.wv[key]\n",
    "\n",
    "word_v = normalize(w2v_dict[myword])\n",
    "print(\"Word2Vec\")\n",
    "display(find_similar_to(word_v, w2v_dict)[:10])\n",
    "\n",
    "\n",
    "print('----'*20)\n",
    "print()\n",
    "\n",
    "########################################\n",
    "### AE note to self: comparison between\n",
    "### count-3000-context + svd-500 (w=5) and\n",
    "### w2v-dim-500 (w=5)\n",
    "\n",
    "# New count-based and Word2Vec models with new configuration\n",
    "num_dims = 3000\n",
    "svddim = 500\n",
    "win = 5\n",
    "\n",
    "ktw = do_word_count(corpus_dir, num_dims)\n",
    "wi = make_word_index(ktw) # word index\n",
    "\n",
    "# Creat new models\n",
    "print('create count matrices')\n",
    "space_3k = make_space(corpus_dir, wi, num_dims, win)\n",
    "print('svd transform')\n",
    "svdspace_3k = svd_transform(space_3k, num_dims, svddim)\n",
    "print('create Word2Vec')\n",
    "corpus = CorpusReader(corpus_dir+'/wikipedia.txt')\n",
    "w2v_new = Word2Vec(sentences=corpus,\n",
    "                     # training options goes here\n",
    "                     size=svddim, max_final_vocab=num_dims, window=win)\n",
    "\n",
    "print('Finished creating new models.')\n",
    "print('-'*10)\n",
    "print(\"\\nWindow = 5, Number of Word = 3000, Reduced Dimention = 500, Word3Vec size = 500\")\n",
    "\n",
    "# find 10 most words that are similar to myword using count-based model\n",
    "word_v = normalize(svdspace_3k[myword])\n",
    "print(\"\\nCount-based Reduced\")\n",
    "display(find_similar_to(word_v, svdspace_3k)[:10])\n",
    "\n",
    "# find 10 most words that are similar to myword using word2vec model\n",
    "# convert w2vecmodel to dict \n",
    "w2vnew_dict = dict({})\n",
    "for key in w2v_new.wv.vocab:\n",
    "    w2vnew_dict[key] = w2v_new.wv[key]\n",
    "\n",
    "word_v = normalize(w2vnew_dict[myword])\n",
    "print(\"Modified Word2Vec\")\n",
    "display(find_similar_to(word_v, w2vnew_dict)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### Answer:\n",
    "\n",
    "We tried to establish comparisons based on algebraic manipulation over `queen`, `king`, `man`, and `woman`. However, we did not find the word `woman` in the count-based model, so we have established another experiment. We will compare the results of capturing the words that have similar semantic meaning with the word `mother`.\n",
    "\n",
    "We equalized the word embeddings' length of the reduced count-based model to be 300 (instead of 5) similar to Word2Vec. The original configuration has a relatively low number of vocabulary and context window size. In the modified configuration, we have increased the number of vocabulary to be 3000 unique words and the context window size to be 5. \n",
    "\n",
    "In both cases, the Word2Vec model performs better over the count-based model; the Word2Vec captured more words that have the same semantic meaning to our target word `mother`.  \n",
    "\n",
    "For the count-based model, the performance did not noticeably change after using the new configuration. On the other hand, the performance of the Word2Vec module increased when we applied the new setting. All words captured by Word2Vec under the new configuration are semantically related to the word `mother`.\n",
    "\n",
    "We noticed that when we used a low value of the context window size, some words with a syntactic relation with our target word appear, such as `her` and `works`. No such words appear as we increased the window size. \n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Some comments, the experiments you do are reasonable, but I'm not sure about the comparison between word2vec and count-based methods in this regard. Because word2vec and count-based methods are very different methods using the same number of dimensions is not very meaningful. So, the number of dimensions in word2vec indicate \"anonymous features\", while in count-based methods the features are not anonymous, they are distinct words. Thus, reasonably the two different methods would have different \"optimal\" number of dimensions. My main point is that \"dimensions\" have different meaning in the two methods, thus trying to equate them to each other is not very indicative of something. \n",
    "\n",
    "In general, it is hard to compare the methods using the same type of modification. Something which have roughly the same meaning is \"window size\" in the two models, so only changing that would be a good contender for comparison (between cout-based and word2vec). However, if you compare two different word2vec models, changing the dimension size makes sense (since it has the same meaning in both models)\n",
    "\n",
    "But, the experiment you are doing (only using woman) is interesting and much simpler (which is good!). Marks=3\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing semantic similarity\n",
    "\n",
    "The file `similarity_judgements.txt` (a copy is included with this notebook or you can download it from [here](https://linux.dobnik.net/oc/index.php/s/9NTlpOJfPWGS56t/download?path=%2Flab4-distributional-data&files=similarity_judgements.txt.zip)) contains 7,576 pairs of words and their lexical and visual similarities (based on the pictures) collected in on online crowd-sourcing data collection using Mechanical Turk as described in [1]. The score range from 1 (highly dissimilar) to 5 (highly similar).\n",
    "\n",
    "The following code will import them into python lists below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of available words to test: 10\n",
      "number of available word pairs to test: 13\n",
      "[(('book', 'bureau'), 1.0, 1.4), (('church', 'radio'), 1.0, 1.0), (('book', 'house'), 1.2, 1.4)]\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [] # test suit word pairs\n",
    "semantic_similarity = [] \n",
    "visual_similarity = []\n",
    "test_vocab = set()\n",
    "\n",
    "filepath = \"/home/guszarzmo@GU.GU.SE/LT2213-v20/lab1/lt2213-lab-1-group-3/zarzouram/problem-set-3/pretrained/similarity_judgements.txt\"\n",
    "\n",
    "# for index, line in enumerate(open('similarity_judgements.txt')):\n",
    "for index, line in enumerate(open(filepath)):\n",
    "    data = line.strip().split('\\t')\n",
    "    if index > 0 and len(data) == 3:\n",
    "        w1, w2 = tuple(data[0].split('#'))\n",
    "        # it will check if both words from each pair exist in the word matrix.\n",
    "        if w1 in space_1k and w2 in space_1k:\n",
    "            word_pairs.append((w1, w2))\n",
    "            test_vocab.update([w1, w2])\n",
    "            semantic_similarity.append(float(data[1]))\n",
    "            visual_similarity.append(float(data[2]))\n",
    "        \n",
    "print(\"number of available words to test:\", len(test_vocab-(test_vocab-set(ktw))))\n",
    "print(\"number of available word pairs to test:\", len(word_pairs))\n",
    "gold_standard = list(zip(word_pairs, visual_similarity, semantic_similarity))\n",
    "print(gold_standard[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test how the cosine similarity between vectors of each of the five spaces compares with the human judgements on the words collected in the previous step. Which of the five spaces best approximates human judgements?\n",
    "\n",
    "For comparison of several scores we can use [Spearman correlation coefficient](https://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient) which is implemented in `scipy.stats.spearmanr` [here](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.stats.spearmanr.html). The values of the Sperman correlation coefficient range from -1, 0 to 1, where 0 indicates no correlation, 1 perfect correaltion and -1 negative correlation. Hence, the greater the number the better. The $p$-values tells us if the coefficient is statistically significant. For this to be the case, it must be less than or equal to $< 0.05$.\n",
    "\n",
    "Here is how you can calculate Spearman's correlation coefficient betweeen the scores of visual similarity and semantic similarity of the available words in the test suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual Similarity vs. Semantic Similarity:\n",
      "rho     = 0.8136\n",
      "p-value = 0.0007\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "rho, pval = stats.spearmanr(semantic_similarity, visual_similarity)\n",
    "print(\"\"\"Visual Similarity vs. Semantic Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the cosine similarity scores of all word pairs in an ordered list using all three matrices. **[2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity function based on Euclidean distance\n",
    "mysim_fn = lambda a, b: 1-distance.cosine(a, b)\n",
    "\n",
    "raw_similarities  = [mysim_fn(space_10k[w1], space_10k[w2]) for w1, w2 in word_pairs]\n",
    "ppmi_similarities = [mysim_fn(ppmispace_10k[w1], ppmispace_10k[w2])  for w1, w2 in word_pairs]\n",
    "svd_similarities  = [mysim_fn(svdspace_10k[w1], svdspace_10k[w2]) for w1, w2 in word_pairs]\n",
    "\n",
    "w2v_similarities     = [mysim_fn(w2v_space[w1], w2v_space[w2])for w1, w2 in word_pairs]\n",
    "w2v_svd_similarities = [mysim_fn(w2v_svd_space[w1], w2v_svd_space[w2]) for w1, w2 in word_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Marks=2\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate correlation coefficients between lists of similarity scores and the real semantic similarity scores from the experiment. The scores of what model best correlate them? Is this expected? **[4 marks + 2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity    rho        p-value   \n",
      "raw          0.3024      0.3153    \n",
      "ppmi         0.7501      0.0031    \n",
      "svd          0.6513      0.0159    \n",
      "w2v          0.6978      0.0080    \n",
      "w2v_svd      0.6716      0.0119    \n"
     ]
    }
   ],
   "source": [
    "# Your code should go here...\n",
    "similarities = [(\"raw\", raw_similarities), (\"ppmi\", ppmi_similarities), (\"svd\", svd_similarities), (\"w2v\", w2v_similarities), (\"w2v_svd\", w2v_svd_similarities)]\n",
    "\n",
    "print(\"{:-^10} {:^10s} {:^13s}\".format(\"Similarity\", \"rho\", \"p-value\"))\n",
    "for name, similarity in similarities:\n",
    "    rho, pval = stats.spearmanr(similarity, semantic_similarity)\n",
    "    print(\"{:<10} {:^10.4f} {:^13.4f}\".format(name, rho, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### Answer:\n",
    "\n",
    "\n",
    "Reducing the dimensions of the count-based model increases the correlation. This indicates that the SVD successfully removed the noise from the term-term matrix.\n",
    "\n",
    "PPMI has higher correlation that raw count-based model. This is expected as PPMI solves the problem associated with the raw count-based model; raw counts are not discribtive and skwed. Words that does not convey information and occur a lot (such as \"the\" and \"of\") will have a high weight. PPMI normalizes the likelihood of co-occurrence of two words (`a`, `b`) to the probability of observing any of them individually. For example, the PPMI of \"the dog\" will be penalize for have the word \"the\", while the PPMI \"old dog\" will not. In that sense, the PPMI performed better than the raw count-based model.\n",
    "\n",
    "Surprisingly, PPMI, which is based on word counting, outperforms the predict-based model (Word2Vec).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Marks=6\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate correlation coefficients between lists of cosine similarity scores and the real visual similarity scores from the experiment. Which similarity model best correlates with them? How do the correlation coefficients compare with those from the previous comparison - and can you speculate why do we get such results? **[2 marks + 6 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity    rho        p-value   \n",
      "raw          0.5882      0.0345    \n",
      "ppmi         0.8445      0.0003    \n",
      "svd          0.7571      0.0027    \n",
      "w2v          0.7396      0.0039    \n",
      "w2v_svd      0.6989      0.0079    \n"
     ]
    }
   ],
   "source": [
    "# Your code should go here...\n",
    "similarities = [(\"raw\", raw_similarities), (\"ppmi\", ppmi_similarities), (\"svd\", svd_similarities), (\"w2v\", w2v_similarities), (\"w2v_svd\", w2v_svd_similarities)]\n",
    "\n",
    "print(\"{:-^10} {:^10s} {:^13s}\".format(\"Similarity\", \"rho\", \"p-value\"))\n",
    "for name, similarity in similarities:\n",
    "    rho, pval = stats.spearmanr(similarity, visual_similarity)\n",
    "    print(\"{:<10} {:^10.4f} {:^13.4f}\".format(name, rho, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here:**\n",
    "\n",
    "We have realized that the correlation of the visual similarity increased, especially for the raw count-based model. If we look at the table below, we find that each pair-of-words could have a high semantic similarity but this is not the case for the visual similarity.  \n",
    "\n",
    "|    W1   \t|   W2   \t| Sem-S \t| Vis-S \t|\n",
    "|:-------:\t|:------:\t|:-----:\t|:-----:\t|\n",
    "| chimp   \t| horse  \t|  3.20 \t|  1.40 \t|\n",
    "| pajamas \t| socks  \t|  3.20 \t|  1.40 \t|\n",
    "| cat     \t| rabbit \t|  4.50 \t|  2.75 \t|\n",
    "\n",
    "\n",
    "We suspected that the failure in capturing the semantic similarity and having a relatively high ratio of disagreement between both semantic and visual similarities lead to this increase in `rho` values for the raw count-based model. However, our further analysis, see the code below, indicates that this method is not indicative. The number of sample data is too low, and all of amples are belong to one category ---no semantic similarity and no visual similarity--- except for one sample data. \n",
    "\n",
    "Raw count-based model fail to capture the similarities for nearly all samples. Yet, there is a noticable improvement in performance when we tried to correlate with the visual similarity. The PPMI fail to capture one sample,\n",
    "however this sample construct a class by its own.\n",
    "\n",
    "Thus, under the current experiment configuration, we believe that these correlation values can not be used as an evaluation of the goodness of the models under test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Types of similarity-------------\n",
      "    raw       ppmi      visual    semantic  \n",
      "   0.60       0.02       1.00       1.40    \n",
      "   0.74       0.09       1.00       1.00    \n",
      "   0.96       0.15       1.20       1.40    \n",
      "   0.92       0.20       4.75       4.25    \n",
      "   0.97       0.15       1.20       1.40    \n",
      "   0.85       0.10       1.00       1.00    \n",
      "   0.87       0.13       1.20       1.40    \n",
      "   0.97       0.18       1.50       1.75    \n",
      "   0.97       0.22       1.20       1.40    \n",
      "   0.96       0.11       1.20       1.20    \n",
      "   0.86       0.13       1.00       1.40    \n",
      "   0.95       0.19       2.40       2.00    \n",
      "   0.93       0.10       1.00       1.00    \n"
     ]
    }
   ],
   "source": [
    "print(\"{:-^44}\".format(\"Types of similarity\"))\n",
    "print(\"{:^11}{:^11}{:^11}{:^11}\".format(\"raw\", \"ppmi\",\"visual\", \"semantic\"))\n",
    "for x in zip(raw_similarities, ppmi_similarities, visual_similarity, semantic_similarity):\n",
    "    print(\"{:^11.2f}{:^11.2f}{:^11.2f}{:^11.2f}\".format(x[0], x[1], x[2], x[3]))\n",
    "# print(\"semantic: \", np.array(raw_similarities))\n",
    "# print(\"visual: \", np.array(visual_similarity))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Good analysis, and you are correct, there are very few data points so the generalizability of the models is low. Marks=8\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion\n",
    "\n",
    "What are the limitations of our approach in this lab? Suggest three ways in which the results could be improved. **[6 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here:**\n",
    "\n",
    "1. Text preprocessing\n",
    "    1. removing functional words, words like `the`, `a`, etc are not indicative. \n",
    "    2. lemmatization, the co-occurrence of `old dog` and `old dogs` should be considered the same.\n",
    "2. Consider using a larger corpus. Many word pairs in human judgment are not found in the corpus, limiting our ability to evaluate our models properly. Consider using the pretrained word embeddings.\n",
    "3. Instead of finding correlation for a continuous scale of human judgment, try to convert the continuous data type to categorical type; what is the difference between 4.25 and 4.75? The same for the model output. A fuzzy function could be used to deal with numbers that are on edge between two categories.\n",
    "4. Dimensionality reduction:\n",
    "    1. Consider using a dimensionality reduction method other than SVD for count-based model\n",
    "    2. Select the number of reduced dimensions that produced the least errors when the original vector is reconstructed back using the reduced vector.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: Reasonable suggestions! Although, I'm not sure what you mean in (3), the difference between 4.25 and 4.75 is precisely 0.5, whatever \"category\" the words are. So, a small difference between the similarity judgments mean there is not much difference, while a large gap indicate there is a large difference. This approach has problems on it's own, such that people imagine different things when \"visually\" comparing dog and cat, if a human imagines both the \"dog\" and \"cat\" as black, they are quite similar, but in shape, or size, they are typically very different. \n",
    "\n",
    "Marks=6\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---AE: 43 points out of 45. I really liked your enthusiasm and analysis in the lab, good job! Something in general to consider: when you are proposing some \"new\" type of analysis or method it, motivating the method is very important. Someone reading it will have a hard time finding the latent factors behind the development, and assesing something without grasping the ins and outs of the method is rather dangerous haha\n",
    "\n",
    "Best,\n",
    "Adam\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature\n",
    "\n",
    "[1] C. Silberer and M. Lapata. Learning grounded meaning representations with autoencoders. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 721–732, Baltimore, Maryland, USA, June 23–25 2014 2014. Association for Computational Linguistics.\n",
    "\n",
    "[2] Y. Bengio, R. Ducharme, P. Vincent, & C. Jauvin (2003). A neural probabilistic language model. Journal of machine learning research, 3(Feb), 1137-1155.\n",
    "\n",
    "[3] Levy, Omer, Yoav Goldberg, and Ido Dagan. \"Improving distributional similarity with lessons learned from word embeddings.\" Transactions of the Association for Computational Linguistics 3 (2015): 211-225.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
