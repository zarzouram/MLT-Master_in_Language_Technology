{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference using Neural Networks\n",
    "Adam Ek\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below.\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the VG part of problem set 3, we will work with neural networks for natural language inference. Our task is: given a premise sentence P and hypothesis H, what entailment relationship holds between them? Is H entailed by P, contradicted by P or neutral towards P?\n",
    "\n",
    "Given a sentence P, if H definitely describe something true given P then it is an **entailment**. If H describe something that's *maybe* true given P, it's **neutral**, and if H describe something that's definitely *false* given P it's a **contradiction**. \n",
    "\n",
    "This definition of inference, and the method we use to solve it, is diffrent from what you've previously worked with. Briefly discuss strengths and weaknesses of using formal semantics versus using statistical methods for natural language inference. **[4 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here**\n",
    "\n",
    "| formal semantics                                              | Deep Learning |\n",
    "|---------------------------------------------------------------|-----------------------------------------------|\n",
    "| Sentences must be parsable.                                   | Can deal with more natural language      |\n",
    "| According to the design, it can deal with word sense ambiguity and othe problems | Word sense ambiguity may affect the performance if not included in the training phase|\n",
    "| Do not need a large data to train, but need a relatively complex world model  | Need large data                               |\n",
    "| Transperant, the output can be linked to the input            | Model is a black box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore natural language inference using neural networks on the SNLI dataset, described in [1]. The dataset can be downloaded [here](https://nlp.stanford.edu/projects/snli/). We prepared a \"simplified\" version, with only the relevant columns [here](https://gubox.box.com/s/idd9b9cfbks4dnhznps0gjgbnrzsvfs4).\n",
    "\n",
    "The (simplified) data is organized as follows (tab-separated values):\n",
    "* Column 1: Premise\n",
    "* Column 2: Hypothesis\n",
    "* Column 3: Relation\n",
    "\n",
    "Like in the previous lab, we'll use torchtext to build a dataloader. You can essentially do the same thing as you did in the last lab, but with our new dataset. **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mytokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def dataloader(path_to_snli, batch_size=8, device=None):\n",
    "\n",
    "    print(\"Loading data...\\n\")\n",
    "\n",
    "    if not device:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    text = Field(tokenize=mytokenizer,\n",
    "                 sequential=True,\n",
    "                 batch_first=True)\n",
    "\n",
    "    label = Field(batch_first=True,\n",
    "                  sequential=False,\n",
    "                  is_target=True)\n",
    "\n",
    "    fields = [(\"premises\", text),\n",
    "              (\"hypothesis\", text),\n",
    "              (\"relation\", label)]\n",
    "\n",
    "    # create tabular datasets\n",
    "    train_ds, dev_ds, test_ds = TabularDataset.splits(\n",
    "        path=path_to_snli,\n",
    "        train=\"simple_snli_1.0_train.csv\",\n",
    "        validation=\"simple_snli_1.0_dev.csv\",\n",
    "        test=\"simple_snli_1.0_test.csv\",\n",
    "        format=\"csv\",\n",
    "        fields=fields,\n",
    "        csv_reader_params={\"delimiter\": \"\\t\"})\n",
    "\n",
    "    text.build_vocab(train_ds, dev_ds, test_ds, min_freq=3)\n",
    "    label.build_vocab(train_ds, dev_ds, test_ds, min_freq=3)\n",
    "\n",
    "    train_iter, dev_iter, test_iter = BucketIterator.splits(\n",
    "        (train_ds, dev_ds, test_ds),\n",
    "        batch_sizes=batch_size,\n",
    "        sort_within_batch=False,\n",
    "        shuffle=True,\n",
    "        repeat=False,\n",
    "        sort_key=lambda x: (len(x.premises), len(x.hypothesis)),\n",
    "        device=device)\n",
    "\n",
    "    print(\"Loading data done.\\n\")\n",
    "\n",
    "    return train_iter, dev_iter, test_iter, label, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll build the model for predicting the relationship between H and P.\n",
    "\n",
    "We will process each sentence using an LSTM. Then, we will construct some representation of the sentence. When we have a representation for H and P, we will combine them into one vector which we can use to predict the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a model described in [2], the BiLSTM with mean/max-pooling model. The procedure for the model is roughly:\n",
    "\n",
    "    1) Encode the Hypothesis and the Premise using a bidirectional LSTM\n",
    "    2) Perform max or mean pooling over the premise and hypothesis\n",
    "    3) Combine the premise and hypothesis into one representation\n",
    "    4) Predict the relationship "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a representation of a sentence\n",
    "\n",
    "Let's first consider step 2 where we perform max/mean pooling. There is a function in pytorch for this, but we'll implement it from scratch. \n",
    "\n",
    "Let's consider the general case, what we want to do for these methods is apply some function $f$ along dimension $i$, and we want to do this for all $i$'s. As an example we consider the matrix S with size ``(N, D)`` where N is the number of words and D the number of dimensions:\n",
    "\n",
    "$S = \\begin{bmatrix}\n",
    "    s_{11} & s_{12} & s_{13} & \\dots  & s_{1d} \\\\\n",
    "    s_{21} & s_{22} & s_{23} & \\dots  & s_{2d} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    s_{n1} & s_{n2} & s_{n3} & \\dots  & s_{nd}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "What we want to do is apply our function $f$ on each dimension, taking the input $s_{1d}, s_{2d}, ..., s_{nd}$ and generating the output $x_d$. \n",
    "\n",
    "You will implement both the max and mean pooling methods. When performing mean-pooling, $f$ will be the mean function and $x$ is the output, thus for each dimension $d$ we calculate:\n",
    "\n",
    "\\begin{equation}\n",
    "x_d = \\frac{1}{N}\\sum_{j=1}^N x_{jd}\n",
    "\\end{equation}\n",
    "\n",
    "When performing max-pooling we do the same thing, but let $f$ be the ``argmax`` function:\n",
    "\n",
    "\\begin{equation}\n",
    "    x_d = f(s_{1d}, s_{2d}, ..., s_{nd}) = argmax(s_{1d}, s_{2d}, ..., s_{nd})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Both of these operations reduce a batch of size ``(batch_size, num_words, dimensions)`` to ``(batch_size, 1, dimensions)`` meaning that we now have created a sentence representation based on the content of the words representations in the sentence (by applying some function $f$ along a dimension). \n",
    "\n",
    "Create a function that takes as input a tensor of size ``(batch_size, num_words, dimensions)`` then performs max or mean pooling and return it. [**6 Marks**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(input_tensor):\n",
    "    # sum word feature in each sent and each batch\n",
    "    # get the index of the max word vector summation\n",
    "    # select based on the max id\n",
    "\n",
    "    batch_size = input_tensor.size(0)\n",
    "    mean_pool = torch.max(input_tensor, 1)[0]\n",
    "    output_tensor = mean_pool.view(batch_size, 1, -1)\n",
    "    return output_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining sentence representations\n",
    "\n",
    "Next, we need to combine the premise and hypothesis into one representation. We will do this by concatenating four tensors (the final size of our tensor $X$ will be ``(batch_size, 1, 4d)`` where ``d`` is the number of dimensions that you use): \n",
    "\n",
    "$$X = [P; H; P \\cdot H; P-H]$$\n",
    "\n",
    "Here, what we do is concatenating P, H, P times H, and the absolute value of P minus H, then return the result.\n",
    "\n",
    "Implement the function. **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_premise_and_hypothesis(hypothesis, premise):\n",
    "    p_minus_h = torch.abs(premise - hypothesis)\n",
    "    p_dot_h = hypothesis * premise\n",
    "    output = torch.cat((premise, hypothesis, p_dot_h, p_minus_h), dim=2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "Finally, we can build the model according to the procedure given previously by using the functions we defined above. Additionaly, in the model you should use *dropout*. For efficiency purposes, it's acceptable to only train the model with either max or mean pooling. \n",
    "\n",
    "Implement the model [**6 marks**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_size,\n",
    "                 bidirectional=True,\n",
    "                 batch_first=True,\n",
    "                 num_layers=1,\n",
    "                 dropout=0.5):\n",
    "\n",
    "        super().__init__()\n",
    "        # your code goes here\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           bidirectional=bidirectional,\n",
    "                           batch_first=batch_first,\n",
    "                           num_layers=num_layers,\n",
    "                           dropout=dropout)\n",
    "        self.classifier = nn.Linear(hidden_dim*8, output_size)\n",
    "\n",
    "    def forward(self, premise, hypothesis):\n",
    "        p_emb = self.embeddings(premise)\n",
    "        h_emb = self.embeddings(hypothesis)\n",
    "        p_encode, _ = self.rnn(p_emb)\n",
    "        h_encode, _ = self.rnn(h_emb)\n",
    "        p_max = pooling(p_encode)\n",
    "        h_max = pooling(h_encode)\n",
    "        x = combine_premise_and_hypothesis(p_max, h_max)\n",
    "        predictions = F.relu(self.classifier(x))\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, implement the training and testing of the model. SNLI can take a very long time to train, so I suggest you only run it for one or two epochs. **[2 marks]** \n",
    "\n",
    "**Tip for efficiency:** *when developing your model, try training and testing the model on one batch (for each epoch) of data to make sure everything works! It's very annoying if you train for N epochs to find out that something went wrong when testing the model, or to find that something goes wrong when moving from epoch 0 to epoch 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, iterator, optimizer, loss_function):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        p = batch.premises\n",
    "        h = batch.hypothesis\n",
    "        outputs = model(p, h)\n",
    "\n",
    "        # predictions = model(batch)\n",
    "        batch_size = batch.relation.size(0)\n",
    "        loss = loss_function(outputs.view(batch_size, -1), batch.relation)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999 or (i % 1000 != 999 and i == len(iterator)-1):\n",
    "            print(f\"  Batch-{i+1:<6d} Loss: {running_loss/(i+1):.3f}\")\n",
    "\n",
    "    return running_loss/len(iterator)\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, iterator, loss_function):\n",
    "    running_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            p = batch.premises\n",
    "            h = batch.hypothesis\n",
    "            outputs = model(p, h)\n",
    "\n",
    "            # predictions = model(batch)\n",
    "            batch_size = batch.relation.size(0)\n",
    "            loss = loss_function(outputs.view(batch_size, -1), batch.relation)\n",
    "\n",
    "            # loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 1000 == 999 or (i % 1000 != 999 and i == len(iterator)-1):\n",
    "                print(f\"  Batch-{i+1:<6d} Loss: {running_loss/(i+1):.3f}\")\n",
    "\n",
    "    return running_loss/len(iterator)\n",
    "\n",
    "\n",
    "def train_eval(model, train_iter, eval_iter, epochs, lr=0.001):\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function = loss_function.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train, evaluate\n",
    "        print(\"Start training...\")\n",
    "        print(f\"\\nepoch: {epoch:2d}\")\n",
    "        _ = train_epoch(model, train_iter, optimizer, loss_function)\n",
    "\n",
    "        print(\"\\nStart Eval...\")\n",
    "        print(f\"\\nepoch: {epoch:2d}\\n\")\n",
    "        _ = evaluate_epoch(model, eval_iter, loss_function)\n",
    "\n",
    "        # TODO: save model that have the best loss or eval metrics ...\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test(model, iterator):\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            p = batch.premises\n",
    "            h = batch.hypothesis\n",
    "            outputs = model(p, h)\n",
    "\n",
    "            relation = batch.relation.tolist()\n",
    "            batch_size = batch.relation.size(0)\n",
    "            prob_dist = F.softmax(outputs.view(batch_size, -1), 0)\n",
    "            prediction = torch.max(prob_dist, 1)[\n",
    "                1].view(-1).tolist()\n",
    "\n",
    "            predictions += prediction\n",
    "            labels += relation\n",
    "\n",
    "            accuracy = accuracy_score(predictions, labels)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data...\n",
      "\n",
      "Loading data done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = batch_size = (64, 32, 32)\n",
    "dataset_path = \\\n",
    "    \"/home/guszarzmo@GU.GU.SE/MLT_Temp/lt2213-v20/dataset/simple_snli_1.0\"\n",
    "train_iter, eval_iter, test_iter, label, text = dataloader(\n",
    "    dataset_path, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start training...\n",
      "\n",
      "epoch:  0\n",
      "  Batch-1000   Loss: 1.009\n",
      "  Batch-2000   Loss: 0.945\n",
      "  Batch-3000   Loss: 0.907\n",
      "  Batch-4000   Loss: 0.881\n",
      "  Batch-5000   Loss: 0.863\n",
      "  Batch-6000   Loss: 0.849\n",
      "  Batch-7000   Loss: 0.837\n",
      "  Batch-8000   Loss: 0.826\n",
      "  Batch-8597   Loss: 0.820\n",
      "\n",
      "Start Eval...\n",
      "\n",
      "epoch:  0\n",
      "\n",
      "  Batch-313    Loss: 0.879\n",
      "Start training...\n",
      "\n",
      "epoch:  1\n",
      "  Batch-1000   Loss: 0.703\n",
      "  Batch-2000   Loss: 0.703\n",
      "  Batch-3000   Loss: 0.701\n",
      "  Batch-4000   Loss: 0.701\n",
      "  Batch-5000   Loss: 0.700\n",
      "  Batch-6000   Loss: 0.698\n",
      "  Batch-7000   Loss: 0.696\n",
      "  Batch-8000   Loss: 0.695\n",
      "  Batch-8597   Loss: 0.694\n",
      "\n",
      "Start Eval...\n",
      "\n",
      "epoch:  1\n",
      "\n",
      "  Batch-313    Loss: 0.813\n",
      "\n",
      "model accuracy:0.51\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(text.vocab)\n",
    "embedding_size = 100\n",
    "hidden_size = 33\n",
    "epochs = 2\n",
    "output_size = len(label.vocab)\n",
    "\n",
    "model = SNLIModel(vocab_size, embedding_size, hidden_size, output_size)\n",
    "model = model.to(device)\n",
    "model = train_eval(model, train_iter, eval_iter, epochs, lr=0.001)\n",
    "metrics = test(model, test_iter)\n",
    "print(f\"\\nmodel accuracy:{metrics:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest a baseline that we can compare our model against **[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest some ways (other than using a baseline) in which we can analyse the models performance **[6 marks]**.\n",
    "\n",
    "1. Using Accuracy, Precision and F1 score in the testing/inference phase\n",
    "2. Using Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest some ways to improve the model **[4 marks]**.\n",
    "\n",
    "1. Model hyperparameter tuning\n",
    "2. Using of pre-trained word vectors and c/c encodeing\n",
    "3. We could use a feedforward layer to encode the sentences instead of pooling, not sure if this will improve the perfromance\n",
    "4. Adding regularization term to the loss function and/or applying dropout to the embedding layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readings\n",
    "\n",
    "[1] Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). \n",
    "\n",
    "[2] Conneau, A., Kiela, D., Schwenk, H., Barrault, L., & Bordes, A. (2017). Supervised learning of universal sentence representations from natural language inference data. arXiv preprint arXiv:1705.02364."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}